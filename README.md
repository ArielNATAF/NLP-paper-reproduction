This repository contains the code, results and Data for the NLP assignement for MLSD in March 2022.

The original work we had to reproduce: 
> Experiments with Universal CEFR Classification  
> Authors: Sowmya Vajjala and Taraka Rama  
> (to appear) In Proceedings of The 13th Workshop on Innovative Use of NLP for Building Educational Applications

* **W18-0515.pdf**, the original paper
* **Nataf Khalbous Chanier Research Article Reproducibility.pdf**, our report
* **results**, folder containg our results. They are the ouptut retrieved using |tee "output...txt" in the console.
* 
# Natural Language Processing : Research Article Reproducibility
## Experiments with Universal CEFR classifications
> Ariel Nataf, Adnene Khalbous, Jean-Baptiste Chanier
> 
> Université de Paris

As part of the Master 2 ”Machine Learning pour la Science des Donn ́ees” at the Universit ́e de Paris, our group of students
was interested in studying, analysing and reproducing results from a research article published in 2018 entitled ”Experiments
with Universal CEFR classifications” (Vajjala and Rama, 2018). The paper builds on the codes used by the original authors
of the paper on the github platform. It offers a solution to a classification problem known as Automated Essay Scoring
(AES), the automatic assignment of grades to student essays based on their language proficiency. The different levels of
expression are based on the Common European Framework of Reference (CEFR). The paper presents a comparison of the rat-
ings obtained with three languages (German, Italian and Czech), using monolingual, cross-lingual and multi-lingual techniques.


